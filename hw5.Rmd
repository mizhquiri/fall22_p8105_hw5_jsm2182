---
title: "HW 5"
output: github_document
---

```{r, include = FALSE, messsage=FALSE, warning=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)


knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))


options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d


set.seed(1) #sets a seed for reproducibility
```

## Problem 2

Load data 

```{r, echo = FALSE, warning = FALSE, message = FALSE}
homicide_rawdf = read_csv("./data/homicide-data.csv")
```
This dataset overviews demographic and geographic data for homicide victims across various cities in the United States. 

```{r}
homicide_cleandf = 
  homicide_rawdf %>% 
  mutate(
    city_state = str_c(city,", ", state)
  )
```


```{r}
all_homicides = 
  homicide_cleandf %>% 
  group_by(city_state) %>% 
  summarize(n_obs = n())
```
```{r}
unsolved_homicides = 
  homicide_cleandf %>% 
  group_by(city_state) %>% 
  filter(
    disposition != "Closed by arrest"
  ) %>% 
  summarize(
    n_obs_unsolved = n()
  )
```

```{r}
homicide_city_state_data = 
  left_join(all_homicides, unsolved_homicides, by = "city_state")

head(homicide_city_state_data)
```



_Baltimore 1 - sample Proportion of Unsolved Homicides to All Homicides_
```{r}

  baltimore_homicides = 
  homicide_city_state_data %>% 
  filter(
    city_state == "Baltimore, MD"
  ) 


  prop.test(baltimore_homicides %>% pull(n_obs_unsolved), baltimore_homicides %>% pull(n_obs)) %>% 
  broom::tidy() %>% 
  select(
    estimate, conf.low, conf.high
  )

```


```{r}
  prop.test(baltimore_homicides %>% pull(n_obs_unsolved), baltimore_homicides %>% pull(n_obs)) %>% 
  broom::tidy() %>% 
  select(
    estimate, conf.low, conf.high
  )

```


We are 95% confident that the true proportion unsolved homicide rates in Baltimore is between 0.627 and 0.663.


```{r}
prop_output = function(df) {
  
 prop_test = 
  prop.test(x = df %>% pull(n_obs_unsolved), n = df %>% pull(n_obs))   

  
return(prop_test)

}
```


```{r}
prop_output(homicide_city_state_data)
```

```{r}
homicide_city_state_data %>%
  prop_output() %>% 
  broom::tidy()
  
```


1. Create a function that computes estimate, conf.low, conf.high

%>%  version
```{r}

prop_output = function(x, n) {
  
prop_df = 
  prop.test(x, n) %>%  
    broom::tidy() %>% 
    select(
      estimate, conf.low, conf.high
    )
  
return(prop_df)

}


```

Finally works
```{r}
prop_output(5,10)
```

Try withouth broom::tidy

```{r}
prop_nobroom = function(x, n) {
  
prop_df = 
  prop.test(x, n)
  
return(prop_df)

}
```


```{r}
prop_nobroom(5, 10)
```
Not in a tidy way
```{r, eval = FALSE}

homicide_city_state_data


map2(x = homicide_city_state_data %>% pull(n_obs_unsolved), y = homicide_city_state_data %>% pull(n_obs), ~prop_nobroom(x = .x, n = .y))

```
Error: Not enough data



```{r, eval = FALSE}
homicide_city_state_data


map2( .x = homicide_city_state_data %>% pull(n_obs_unsolved), .y = homicide_city_state_data %>% pull(n_obs), ~prop.test(x = .x, n = .y))
```


2. map the data

VERSION 1



Using basic prop.test
```{r, eval = FALSE}

homicide_city_state_data %>% 
  mutate(
    proportion_test = map2(n_obs_unsolved, n_obs,prop.test)) 


```
Using my custom code WITH BROOM

```{r, eval = FALSE}
homicide_city_state_data %>% 
  mutate(
    prop = 
      map2(.x = n_obs_unsolved, .y = n_obs, ~prop_output(x = .x, n = .y))
  ) 
```



Using my native code WITH NO BROOM



```{r, eval = FALSE}
homicide_city_state_data %>% 
  mutate(
    prop = 
      map2(.x = n_obs_unsolved, .y = n_obs, ~prop_nobroom(x = .x, n = .y))
  ) 
```


Using my custom code with no broom + nest data 





```{r}
sim_t_test = function(true_mean) {
  sample = rnorm(30, mean = 0)
  
  test_results = t.test(sample) %>% 
  broom::tidy()
}

expand_grid(
  true_mean = 0:6, 
  iter = 1:5
)
```

Above, diff sample/diff sample mean but consistent true mean which is the input

Once you have the plot, it's all after you run the simulation 
group_by + summarize for the true mean & summarize how often the null was rejected

group_by averages 

If all you see are results where p< 0.5 --> publication bias; + low power 
 You end up seeing results which are different than true 

## Problem 2
 
```{r}

```

## Problem 3


 VERSION 1: looks up to date
```{r}

sim_mean_sd = function(mu) {

   x = rnorm(n = 30, mean = mu, sd = 5) 
   
  output = t.test(x) %>% broom::tidy()
  
 }

a = sim_mean_sd(0)
a

#mapping into my input called mean which is named in the dataset. In the function, i have a variable called mu. I am telling the function that I have a variable that is equal to the object mean. 



sim_results_zero_df = 
  expand_grid(
    iter = 1:10, 
    mean = 0) %>% 
  mutate(
    estimate_df = 
      map(mean, sim_mean_sd)
  ) %>% unnest(estimate_df) %>% 
    select(iter, mean, p.value, estimate)

sim_results_zero_df



sim_results_df = 
  expand_grid(
    iter = 1:10,
    mean = c(1,2,3,4,5,6)) %>% 
  mutate(
    estimate_df = 
      map(mean, sim_mean_sd)
  ) %>% unnest(estimate_df) %>% 
  select(iter, mean, p.value, estimate)

sim_results_df


```


`sim_results_df` is the dataset I will work on. 

t. test 

1. Hypothesis statements
- H0: mean = 0 is true
- H1: mean = 0 is not true. 

2. define your alpha: alpha = 0.05

3. calculate your test statistic and compare

4. Compare your p-value for each row
 If p< alpha, then reject H0
 If p !< alpha, then fail to reject H0 

```{r}

sim_decision = 
  sim_results_df %>%
  mutate(
    compare_to_alpha = ifelse(p.value < 0.05, 1, 0)
  ) %>% 
  group_by(mean, compare_to_alpha) %>% 
  filter(
    compare_to_alpha == 1
  ) %>% 
  summarize(
    n_rej = n()
  ) %>% 
  mutate(
    prop = n_rej/10
  )
  

sim_decision
```
```{r}
sim_decision %>% 
  ggplot(aes(x = mean, y = prop)) +
  geom_point() + 
  labs(
    x = "True Mean",
    y = "Likelihood of Rejecting H0",
    title = "Power"
    ) 
```

Make a plot showing the average estimate of μ^ on the y axis and the true value of μ on the x axis. Make a second plot (or overlay on the first) the average estimate of μ^ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis. Is the sample average of μ^ across tests for which the null is rejected approximately equal to the true value of μ? Why or why not
```{r}
 plot_compare_means = 
  sim_results_df %>%
  ggplot(aes(x = mean, y = estimate)) + geom_point() + 
  labs(
    x = "True Mean",
    y = "Sample Means",
    title = "Comparing Mu vs Mu-hat"
    ) 


sim_rej = 
  sim_results_df %>%
  mutate(
    compare_to_alpha = ifelse(p.value < 0.05, 1, 0)
  ) %>% 
  group_by(mean, compare_to_alpha, estimate) %>% 
  filter(
    compare_to_alpha == 1
  ) %>% 
  ggplot(
    aes(x = mean, y = estimate)) + geom_point() + 
  labs(
    x = "True Mean",
    y = "Sample Means",
    title = "Comparing Mu vs Mu-hat for which p< 0.05"
    ) 
  

plot_compare_means / sim_rej


```

