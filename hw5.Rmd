---
title: "HW 5"
output: github_document
---

```{r, include = FALSE, messsage=FALSE, warning=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)


knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))


options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d


set.seed(1) #sets a seed for reproducibility
```


## Problem 1 

## Problem 2



```{r, echo = FALSE, warning = FALSE, message = FALSE}
homicide_rawdf = read_csv("./data/homicide-data.csv")
```
_Description of raw data_ This dataset overviews demographic and geographic data for homicide victims across various cities in the United States. It has `n rows(homicide_rawdf)` rows and `ncols(homicide_rawdf)` columns.

Steps: 

1. Cleaned the data

```{r, echo = FALSE}
homicide_cleandf = 
  homicide_rawdf %>% 
  mutate(
    city_state = str_c(city,", ", state)
  ) %>% 
  relocate(city_state)
```

2. Calculated the # of all homicides (n) and unsolved homicides (x)
```{r, echo = FALSE}
all_homicides = 
  homicide_cleandf %>% 
  group_by(city_state) %>% 
  summarize(n_obs = n())
```
```{r}
unsolved_homicides = 
  homicide_cleandf %>% 
  group_by(city_state) %>% 
  filter(
    disposition != "Closed by arrest"
  ) %>% 
  summarize(
    n_obs_unsolved = n()
  )
```

3. Added these #s to the dataset 
```{r}
homicide_city_state_data = 
  left_join(all_homicides, unsolved_homicides, by = "city_state") %>% 
  na.omit()

head(homicide_city_state_data)

```



_Baltimore 1 - sample Proportion of Unsolved Homicides to All Homicides_
```{r}

  baltimore_homicides = 
  homicide_city_state_data %>% 
  group_by(city_state, n_obs, n_obs_unsolved) %>% 
  summarize() %>% 
  filter(
    city_state == "Baltimore, MD"
  ) 


  prop.test(baltimore_homicides %>% pull(n_obs_unsolved), baltimore_homicides %>% pull(n_obs)) %>% 
  broom::tidy() %>% 
  select(
    estimate, conf.low, conf.high
  ) %>% 
    knitr::kable(2, caption = "Baltimore, MD 1 - Sample Proportion of Unsolved Homicides")

```


We are 95% confident that the true proportion of unsolved homicide rates in Baltimore is between 0.627 and 0.663.


```{r, echo = FALSE}

  results = homicide_city_state_data %>% 
    group_by(city_state, n_obs_unsolved, n_obs) %>% 
    summarize()

head(results)
```


_Created a function that runs prop.test given certain inputs

```{r}

prop_function = function(x, n) {
  
  
 prop_test = 
  prop.test(x, n) %>% 
  broom::tidy() %>% 
  select(estimate, conf.low, conf.high)

  
return(prop_test)

}


```



_Applied in a tidy way_


```{r, message = FALSE, warning = FALSE}
data_final = 
  homicide_city_state_data %>% 
  mutate(
    proportion_test = map2(n_obs_unsolved, n_obs, prop_function)
    ) %>% 
  unnest() %>% 
  mutate(
    city_state = as.factor(city_state),
    city_state = fct_reorder(city_state, estimate)
  )
    
```


_Plot_


```{r}


data_final %>% 
  ggplot(aes(x = city_state, y = estimate)) + 
  geom_boxplot() + 
  geom_errorbar(
    aes(ymin = conf.low, ymax = conf.high), width = .2, 
    position = position_dodge(.9)
  ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) + 
  theme(legend.position = "right") + 
  labs(
    x = "Cities",
    y = "Proportions of Unsolved to All Homicides",
    title = "Estimates and CIs for each city"
    ) 
  
  
```



## Problem 3


1. First set the following design elements, Set μ=0. Generate 5000 datasets from the modelor each dataset, save μ^ and the p-value arising from a test of H:μ=0 using α=0.05. Hint: to obtain the estimate and p-value, use broom::tidy to clean the output of t.test.
```{r}

sim_mean_sd = function(mu) {

   x = rnorm(n = 30, mean = mu, sd = 5) 
   
  output = t.test(x) %>% broom::tidy()
  
 }



#mapping into my input called mean which is named in the dataset. In the function, i have a variable called mu. I am telling the function that I have a variable that is equal to the object mean. 



sim_results_zero_df = 
  expand_grid(
    iter = 1:5000, 
    mean = 0) %>% 
  mutate(
    estimate_df = 
      map(mean, sim_mean_sd)
  ) %>% unnest(estimate_df) %>% 
    select(iter, mean, p.value, estimate)

head(sim_results_zero_df)



```


Repeat the above for μ={1,2,3,4,5,6},
```{r}
sim_results_df = 
  expand_grid(
    iter = 1:5000,
    mean = c(1,2,3,4,5,6)) %>% 
  mutate(
    estimate_df = 
      map(mean, sim_mean_sd)
  ) %>% unnest(estimate_df) %>% 
  select(iter, mean, p.value, estimate)

head(sim_results_df)

```

`sim_results_df` is the dataset I will work on. 

t. test 

1. Hypothesis statements
- H0: mean = 0 is true
- H1: mean = 0 is not true. 

2. define your alpha: alpha = 0.05

3. calculate your test statistic and compare

4. Compare your p-value for each row
 If p< alpha, then reject H0
 If p !< alpha, then fail to reject H0 

```{r}

sim_decision = 
  sim_results_df %>%
  mutate(
    compare_to_alpha = ifelse(p.value < 0.05, 1, 0)
  ) %>% 
  group_by(mean, compare_to_alpha) %>% 
  filter(
    compare_to_alpha == 1
  ) %>% 
  summarize(
    n_rej = n()
  ) %>% 
  mutate(
    prop = n_rej/5000
  )
  

sim_decision
```

* Note more elegant way may have been to use the denominator as the minimum of the iteration value or add a new column called 5000 for each observation.


Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.

ANS: The larger the effect size the larger the power. 

```{r}
sim_decision %>% 
  ggplot(aes(x = mean, y = prop)) +
  geom_point() + 
  labs(
    x = "True Mean",
    y = "Likelihood of Rejecting H0",
    title = "Power"
    ) 
```

Make a plot showing the average estimate of μ^ on the y axis and the true value of μ on the x axis. Make a second plot (or overlay on the first) the average estimate of μ^ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis. Is the sample average of μ^ across tests for which the null is rejected approximately equal to the true value of μ? Why or why not


No, the sample average of μ^ across tests for which the null is rejected is NOT approximately equal to the true value of μ. This makes sense as there is sufficient evidence to reject the null hypothesis. 

```{r}
 plot_compare_means = 
  sim_results_df %>%
  ggplot(aes(x = mean, y = estimate)) + geom_point() + 
  labs(
    x = "True Mean",
    y = "Sample Means",
    title = "Comparing Mu vs Mu-hat"
    ) 


sim_rej = 
  sim_results_df %>%
  mutate(
    compare_to_alpha = ifelse(p.value < 0.05, 1, 0)
  ) %>% 
  group_by(mean, compare_to_alpha, estimate) %>% 
  filter(
    compare_to_alpha == 1
  ) %>% 
  ggplot(
    aes(x = mean, y = estimate)) + geom_point() + 
  labs(
    x = "True Mean",
    y = "Sample Means",
    title = "Comparing Mu vs Mu-hat for which p< 0.05"
    ) 
  

plot_compare_means / sim_rej


```

